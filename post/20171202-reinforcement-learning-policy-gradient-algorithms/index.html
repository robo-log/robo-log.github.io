
<!DOCTYPE html>
<html lang="ja">
<head>

  
  <meta charset="UTF-8">
  <title>
    強化学習についてまとめる(4) 方策勾配に基づくアルゴリズム、Actor-Critic | ROBO LOG
  </title>


  
  <meta name="viewport" content="width=device-width,user-scalable=no,maximum-scale=1,initial-scale=1">

  
  <link rel="canonical" href="http://blog.syundo.org/post/20171202-reinforcement-learning-policy-gradient-algorithms/"/>

  
  <link rel="stylesheet" href="/css/sanitize.css">
  <link rel="stylesheet" href="/css/responsive.css">
  <link rel="stylesheet" href="/css/highlight_monokai.css">
  <link rel="stylesheet" href="/css/theme.css">
  <link rel="stylesheet" href="/css/custom.css">

  
  <link href="http://blog.syundo.orgindex.xml" rel="alternate" type="application/rss+xml" title="ROBO LOG" />
  <link href="http://blog.syundo.orgindex.xml" rel="feed" type="application/rss+xml" title="ROBO LOG" />

  
	<script type="text/javascript">var switchTo5x=true;</script>
	<script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script>
	<script type="text/javascript">stLight.options({publisher: "02e11161-0b6b-46d7-9b85-d7ed58578dfd", doNotHash: true, doNotCopy: true, hashAddressBar: false});</script>


</head>



<body>
<div class="container">

  
  <header role="banner">
    <div class="row gutters">
      <div id="site-title" class="col span_6">
        <h1><a href="http://blog.syundo.org">ROBO LOG</a></h1>
        <h2>つくりたいものをつくる</h2>
      </div>
      <div id="social" class="col span_6">
        <ul>
          <li><a href="https://twitter.com/ksyundo" target="_blank">Twitter</a></li>
          
          <li><a href="https://github.com/syundo0730" target="_blank">GitHub</a></li>
          
        </ul>
      </div>
    </div>
  </header>


  
  <main id="single" role="main">
    <div class="article-header">
      <h1>強化学習についてまとめる(4) 方策勾配に基づくアルゴリズム、Actor-Critic</h1>
      <div class="meta">
        Dec 2, 2017 &nbsp;
        
      </div>
    </div>
    <article>
      

<p>前回は方策の勾配の求め方、勾配の分散を減少させるための、baselineを導入するところまでまとめた。
今回は、方策勾配を用いて方策を更新する実際のアルゴリズムについて扱う。</p>

<h1 id="vanilla-policy-gradient">vanilla policy gradient</h1>

<p>baselineの調整と方策の更新を逐次的に更新していくという、方策勾配法の基本的な方法に則った基本的なアルゴリズムを、vanilla policy gradient method と呼ぶことにする。
vanilla policy gradient methodの擬似コードは以下のようになる。</p>

<ol>
<li>パラメタ $\theta$, ベースライン$b$の初期化</li>
<li>$for$ $i=1,2,\dots$ $do$</li>
<li>現在の方策に従って行動し、復数パスを収集し、$R_t = \sum_{t&rsquo;=t}^{H-1} \gamma^{t&rsquo;-t} R_{t&rsquo;}$を計算する。</li>
<li>$|R_t - b|^2$ を最小にするようにbaselineを調整する</li>
<li>$\hat{g} = \sum_{t=0}^H \nabla_{\theta} \log \pi_{\theta} (u_t^{(i)} | s_t^{(i)}) (R(\tau^{(i)}) - b)$で勾配を更新する</li>
<li>$end$ $for$</li>
</ol>

<p>baselineの調整と、勾配の更新を繰り返していき、方策を最適化する。</p>

<h2 id="reinforce-アルゴリズム">REINFORCE アルゴリズム</h2>

<p>上記の復数パスの情報を使って計算した$R_t$の代わりに、そのときどきの報酬$R_t$を使う方法は <strong>REINFORCE</strong> アルゴリズムとして知られている。
baselineとしては報酬の平均値$\bar{b} = \frac{1}{MT} \sum_{m=1}^M \sum_{t=1}^T R_t^m$がよく用いられるらしい。</p>

<h1 id="actor-critic">Actor-Critic</h1>

<p>baselineを導入したとこで、方策の更新は、方策の分散を小さくする評価部と、方策を更新する部分の2つに分けられることがわかる。
ここで、baselineとして、価値関数$V^{\pi}$を使うと
ここで、$R(\tau) = \sum_{t=0}^H R(s_t, u_t)$の代わりに行動価値関数$Q^{\pi}(s, a)$を、baselineとして価値関数$V^{\pi}(s)$を使うことにする。
baselineとして状態$s$の関数を用いても、勾配の平均値には影響がないため、baselineとして採用できる。</p>

<p>以下の行動価値感数と状態価値関数の差分$A^{\pi}(s, a)$をアドバンテージ関数と呼ぶ。
\begin{equation}
A^{\pi}(s, a) = Q^{\pi}(s, a) - V^{\pi}(s)
\end{equation}</p>

<p>アドバンテージを使って、勾配は
\begin{equation}
\hat{g} = \frac{1}{m} \sum_{i=0}^m \sum_{t=0}^H \nabla_{\theta} \log \pi_{\theta} (u_t^{(i)} | s_t^{(i)}) A^{\pi}(s, a)
\label{eq:base_lined_policy_gradient}
\end{equation}
で更新できる。
このアドバンテージを小さくする <strong>Critic</strong> と方策を更新する <strong>Actor</strong> を組み合わせた方法全般を <strong>Actor-Critic</strong> 法と呼ぶ。</p>


      
			<div id="share-this" class="col span_10">
				<span class='st_twitter_large' displayText='Tweet'></span>
				<span class='st_facebook_large' displayText='Facebook'></span>
				<span class='st_hatena_large' displayText='Hatena'></span>
				<span class='st_linkedin_large' displayText='LinkedIn'></span>
				<span class='st_email_large' displayText='Email'></span>
			</div>
    </article>
    
 <aside><div id="disqus_thread"></div></aside> 

<script type="text/javascript">
     
    var disqus_shortname = 'robolog';

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

  </main>

  <nav class="pagination">
    
      <span class="previous">&larr; <a href="http://blog.syundo.org/post/20171117-reinforcement-learning-policy-gradient/" rel="prev">強化学習についてまとめる(3) 方策勾配</a></span>
    
    
      <span class="next"><a href="http://blog.syundo.org/post/20171203-cpg-and-walk/" rel="next">非線形振動子の同期を用いた歩行</a> &rarr;</span>
    
  </nav>


  
  <footer role="contentinfo">
    <div style="text-align:center;">
      <img src="/images/profile.jpeg" width="64" height="64"><br>
      Written by Shundo Kishi
    </div>
  </footer>


</div>

<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-21014159-4', 'auto');
	ga('send', 'pageview');
</script>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    displayAlign: "left",
    displayIndent: "2em",
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    TeX: { equationNumbers: { autoNumber: "AMS" }}
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
  });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
  });
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>

