<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>紹介記事 on ROBO LOG</title>
    <link>http://blog.syundo.org/categories/%E7%B4%B9%E4%BB%8B%E8%A8%98%E4%BA%8B/</link>
    <description>Recent content in 紹介記事 on ROBO LOG</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 18 May 2015 01:26:10 +0900</lastBuildDate>
    
	<atom:link href="http://blog.syundo.org/categories/%E7%B4%B9%E4%BB%8B%E8%A8%98%E4%BA%8B/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>C&#43;&#43;初心者会に参加してきた</title>
      <link>http://blog.syundo.org/post/1154/</link>
      <pubDate>Mon, 18 May 2015 01:26:10 +0900</pubDate>
      
      <guid>http://blog.syundo.org/post/1154/</guid>
      <description>歌舞伎座.tech#8「C++初心者会」に参加してきた。 http://kbkz.connpass.com/event/13905/
初めて勉強会での発表ということもした（ただしLT)
発表資料はこちら http://www.slideshare.net/syundo/c-48237620
ニコ生はこちら http://live.nicovideo.jp/gate/lv220960718
メモを取って即時公開してくださっているひとがいた。 http://www.shigemk2.com/archive/category/C%2B%2B
私はLTでC++を使って開発できるマイコンボードの例としてmbedを紹介した。 だが、問題はmbedのコンパイラにあった。 C++界隈の人たちの興味はC++11，14、さらにはC++17にあるのだ。 対してmbedオンラインコンパイラはC++98だ。 C++98のことなんてもう忘却の彼方にあるし、取るに足りないことなのだ（実際僕もそう思う）。
mbedの開発環境は不自由だ。 ネット環境がないとコンパイルできないとかザコだ。 なぜそんな環境に拘っているのか？ そのご指摘はまさにその通りだと思う。
arm向けの自由なコンパイラがあるんだから、mbedはオンラインコンパイラに頼るエコシステムにすべきじゃなかったのだ。 オンラインコンパイラが無ければmbedは広まらなかったか？ 僕はそうは思わない。Arduinoの開発環境はローカルの開発環境だが超流行っているじゃないか。 Coretex-M3の強い計算機能力を発揮して楽しくC++開発できることがmbedの強みだ。 Arduinoなんて目じゃない。
それなのにコンパイラがC++98/03準拠というのはあんまりじゃないか。 mbedのコミュニティのことを考え、自分のしたい開発のことを考え、もやもやしている&amp;hellip;
C++界隈の人たちというのは濃い、強い。 自分ももっと技術力を高めて本当のプログラマになりたいと思った。
これまで聞いたこと無いキーワードや，聞いたことあったがよく知らないことをたくさん知れた。 調べて勉強してもっとC++をわかりたい。</description>
    </item>
    
    <item>
      <title>Pepper Tech Festival 2014に行ってきた</title>
      <link>http://blog.syundo.org/post/984/</link>
      <pubDate>Sun, 21 Sep 2014 23:49:55 +0900</pubDate>
      
      <guid>http://blog.syundo.org/post/984/</guid>
      <description>昨日9月20日に開催されたPepper Tech Festival(http://www.softbank.jp/robot/special/techfes/live/)に当選したので行ってきました．
当日の12時にpepperが開発者向けに予約開始されるということで，Pepperやその開発環境に関する情報が紹介されるという触れ込みのイベントでした．
当日説明された，開発者向けのパックの内容についてはすでにこのサイトにて公開されています．
(http://www.softbank.jp/robot/special/tech/)
開演時間の30分前に会場に入るとすでに席の半分以上が埋まっていました．ベルサールのWEBサイトによると1000人～1600人が入る部屋らしいです．マジでこれだけの人間がpepperのためだけに来たのか！？浮かれすぎじゃないか！？そしてソフトバンクはどれだけ本気なんだ！？ととにかく興奮しました． 
会場まで行った人への特典は，PepperTechFesのTシャツ，ステッカー，缶バッジ，そしてUSBに入ったPepper開発用の先行公開SDKでした． 
ただしSDKは先行公開版なので，デフォルトのロボットがNAOになっていたり，Pepper相当のモデルの名前が開発中のコードネーム（Juliet）だったりします．SDKについてはすでに会場で作業を進めた人の報告(http://qiita.com/Cocominap/items/93f9f9b8806f9ddaa513) や，秋葉原アトリエの中の人からの説明が出ています．(http://qiita.com/Atelier-Akihabara/items/c5f57358a7b333eef397)
イベント会場は講演会場と展示会場に分かれていて，それぞれ楽しめました．
講演では，Androidアプリの開発者　安生 真 さん，大阪大学基礎工学研究科　石黒 浩 教授，チームラボ代表　猪子 寿之 さん，明和電機　土佐 信道 社長によるパネルディスカッションが興味深かったです．  1→10designが製作し展示会場でも稼働していた，2台のpepperと人間の3人で会話できるデモについて石黒先生が言及されたのがきっかけでロボットと社会性について話が展開していきました．石黒先生が仰るには人間とロボットの会話があまりうまくいっていなくても，ロボット同士が流暢に会話していれば，場としては会話が成立している感じが高まり，会話の違和感が少なくなるとのことです．石黒先生自身も同様な実験を行われているようで（ちゃんと論文を追ってないのでわからないすいません），先生のトークの勢いが止まりませんでした．
猪子さんが，pepperだけ100台くらい居る部屋を作って眺めたいと話すと，水槽の中に居る金魚を外から見るより，中に入って見たほうが楽しいに違いないというような話になっていき，道端でpepper同士が会ったりしたら挨拶するようにしたらおもしろい，などという話に発展していきました．会場のみなが大爆笑の素晴らしいディスカッションでした．
私も実際に1→10designさんのデモを体験してみました．pepperは1台でもわりと勝手に話を進めていく傾向があるように思いますが，2台になるともう完全にトークの主導権を握られてしまい，敗北感を感じました．アニメ攻殻機動隊において，群れて勝手に話しているタチコマに対して人間が少し苛ついた感じで接しているシーンを思い起こしました．仲間外れにされているのがつらいと同時に，pepperにはpepperの生活があるから仕方ないと自然にロボットの人格（ロボ格）を認めることができるようでした．ロボットに社会を形成させたらどうなるか，という話はロボットの知能に深く関わっている話であります．私もpepperに期待しているのは社会性からくる知性とはどんなものか検証してほしいということです．pepperほどの性能のロボットがとりあえず数百台日本に流通するということで，成果が出てきそうな気がします．
展示の中で私が面白いと思ったのはユカイ工学株式会社さんの「マホウノツエ」というデモです． 
pepperに学習赤外線リモコン（IR kit）を内蔵した魔法の杖を持たせることで，pepperに話しかけて家電を操作することができます．このような使い方は誰でも思いつくものですし，「ロビ」もデモでやっていたりするのですが，実際に人間大のロボットが自分の命令で動く様子を見るとインターフェースとしてのヒューマノイドは喧伝されている程度には役に立つのかもしれないと思いました．こういう用途ではスマホに話しかけるのでは駄目なのか？という問題がありますが，少なくとも人間に依頼するように自然に操作できるのはヒューマノイドの持つ力だと思います．それに今後赤外線リモコンだけでなく，ゲームのコントローラでも掃除機でも，なんでも持たせられるようになると更にpepperの価値が高まってくるでしょう．一般物体のマニピュレーションなんてとんでもなく難しい問題ですが，みんなでやれば誰かがなんとかしてくれるんじゃないですかねぇ！？（無責任
TechFesに参加した１日は朝の10時半から19時半までpepperだらけの一日でした．あれだけ高機能なロボットであっても，近くに何台も居るとだんだん慣れてきました．懇親会の間，ビールを片手に何度もpepperの頭をパンパン叩き，体をどつき，指をグニグニしてると，ロボットの居る生活がそんなに遠くないようにさえ思えてきたのでした．
その他に思ったこと，メモなど １，無意識をプログラムするのが重要なんじゃないですかね！ →pepperの内部でバックグラウンド動作しているプログラムとしては，外乱に耐えてバランスをとるもの，周囲の状況と自分の姿勢を把握して衝突回避するもの，などがあるようですが，この手のバックグラウンド動作するプログラムをどんどん増やしていくことがロボットの賢さを高めるのに効果的なんだろうなと思いました． 例えば音声認識に関していえば，会話のある時点のセンテンスを認識するだけでなく，それ以前の人間対人間の会話を聞いていたり，テレビの音をなんとなく聞いていたりというのが自然な会話に役立つんじゃないかと思います．画像認識なども同様なことが言えます．これは意識とは何かということにも繋がっていくと思うのですが&amp;hellip;．現時点のSDKでは内部でバックグラウンド動作するソフトの開発はできないらしいです．今後の展開を期待します．
２．pepperの人工知能って何？ →pepperの文脈で人工知能と言っているのは，ひとつは音声，画像を入力とするニューラルネットワークのことのようです．Deep Learningで学習しているらしいです．例えば，怒った顔を見せれば，怒っているという判定が出るようなユニットです． その他に人工知能っぽいものとしてはSLAMが実装されているようです．部屋のマップを作って自己位置同定をしているようだ......という話を聞きました． ３．pepperの開発をすれば最先端の職業であるロボットクリエーターになれるんですよ！！あなたたちが第一人者ですよ！ →共通ハードウェアで開発していく形がロボットの開発速度を高めていくことは間違いなく，このサイズのロボットが流通することにはものすごい意味を感じています．でも，いちユーザーが職業にできるような盛り上がりになるかはわかりません． ４．ロボット作るのが趣味な僕らはどうしたらいい？ pepper登場以前： あの大学でやってるあれみたいなのやりたい，アシモみたいなのやりたい，etc.→欲しい→でも高くて買えない→じゃあ自分でつくろう！ pepperが現れた後の世界： 君のロボットがやってるそれ，pepperなら簡単にできるよ！pepper買えばいいじゃん！！
あああああああああああああああああああああああああ！
僕「pepperなんか知らねぇよ！俺は俺のロボットを作るんじゃい！」
そしてpepperを手にした皆はコミュニティの力を集結して素晴らしいロボットを作っていくのでしためでたしめでたし．
僕「（真顔）」
５．値段について →pepperを買うには，本体価格213840円+使用料9800円×36ヶ月=566640円支払う必要があります．さすがに使用料含めると部品代よりかは安いと言えないと思いますが，アルデバランのNAOの価格が97万であるのと比べると安いと思います． みなさんどうですか！？先着順じゃないから抽選で200人に選ばれれば買えますよ！
http://www.softbank.jp/robot/special/tech/reserve/ 
おわり．</description>
    </item>
    
    <item>
      <title>正直舐めてた「X-RHex」</title>
      <link>http://blog.syundo.org/post/891/</link>
      <pubDate>Sun, 30 Jan 2011 00:53:06 +0900</pubDate>
      
      <guid>http://blog.syundo.org/post/891/</guid>
      <description>先日、ペンシルベニア大学の「X-RHex」について記事を書いたが6足ロボット「X-RHex」
正直なところ、
「まぁちょっと思いつけば作れるんじゃない？こんなくらい」などと思っていた（爆死
しかし私はとんでもない動画をみつけてしまった。
もはやロボットにしておくにはもったいない愛くるロボット「X-RHex」が更なる進化した姿を披露
 これはさまざまなバージョンのX-RHexの動画をまとめたもので、X-RHexの開発記録である。
まず第一に、岩場や草原などの不整地を走行するには、普通のタイヤより圧倒的に速い！ということを再認識した。この一見簡単なように見える脚の構造自体がものすごく偉大な発見なのだ！！
そして動画の中でカメラを使って色を認識してボールを追いかけたり、ライントレースをしているところがある。非常に完成度の高いシステムなのである！！
最後に、最も驚いたところは、私が2足ロボット好きなこともあるが、3:00あたりのbiped mode（2足歩行モード）である！！なんともちょこちょこと安定して歩く（むしろ走っている）じゃないか！！
本当にアメリカの研究者はこの手の制御がうまい！！それになによりもこんなことやってる暇があるのがすごいのではないか？ちょっと2本脚で歩かせてみようぜ！ってできるものなのか！？
いやぁ。すごい。
本当に驚いたんですよ。見つけてよかった。</description>
    </item>
    
    <item>
      <title>6足ロボット「X-RHex」</title>
      <link>http://blog.syundo.org/post/887/</link>
      <pubDate>Tue, 25 Jan 2011 21:37:04 +0900</pubDate>
      
      <guid>http://blog.syundo.org/post/887/</guid>
      <description>GetRoboBlogさんの記事を見た感想。
足が両側で2＋1本ずつ動く6足ロボット「X-RHex」
 ペンシルベニア大学のロボットらしい。
動画の1:00のあたりで全部の足が浮いている瞬間がカメラに捕らえられている。
特別な制御をしているみたいでもないのに、走行状態になっているんだー。
どうもシミュレーションはしてあるみたいだけど。
脚の柔軟さがポイントなのかも。
二足ロボットにしても脚の構造自体が非常に重要みたいだし↓
日本のアスリート・ロボット、世界を駆け巡る
 これもまだ何も制御してないのに人間の走りそのものだよなぁ。
やっぱ構造は重要。</description>
    </item>
    
  </channel>
</rss>